{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind\n",
    "import sklearn\n",
    "import scipy\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinkful's Feedback Analysis Challenge\n",
    "\n",
    "Data Source: https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences\n",
    "\n",
    "Building my own Naive Bayes Model to classify feedback sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  score\n",
       "0  So there is no way for me to plug it in here i...      0\n",
       "1                        Good case, Excellent value.      1\n",
       "2                             Great for the jawbone.      1\n",
       "3  Tied to charger for conversations lasting more...      0\n",
       "4                                  The mic is great.      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "df = pd.read_csv('sentiment_labelled_sentences/amazon_cells_labelled.txt',\n",
    "                 delimiter='\\t',\n",
    "                 header=None,\n",
    "                 names=['text', 'score'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first attempt... basically copying the thinkful naive bayes spam filter guided example\n",
    "\n",
    "def naive_bayes_take_one (dataframe):\n",
    "    \n",
    "    \"\"\"Train and test naive bayes \n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        dataframe (pd.DataFrame): \n",
    "            dataframe to use\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        total_points: \n",
    "            total number of texts classified\n",
    "        wrong_points: \n",
    "            number of texts incorrectly classified\n",
    "        score: \n",
    "            percent correctly classified\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    #cast everything to lowercase to make it easier to match words\n",
    "    df = dataframe\n",
    "    df = df.apply(lambda x: x.astype(str).str.lower())\n",
    "    \n",
    "    #picking keywords associated with good reviews\n",
    "    keywords = ['good', 'great', 'excellent', 'beautiful', 'best', 'satisfied']\n",
    "\n",
    "    for key in keywords:\n",
    "        # Noted adding spaces around keyword to make sure matching on word and not pattern\n",
    "        df[str(key)] = df.text.str.contains(\n",
    "            ' ' + str(key) + ' ',\n",
    "            case=True\n",
    "        )\n",
    "\n",
    "    data = df[keywords]\n",
    "    target = df['score']\n",
    "    \n",
    "    # Our data is binary / boolean so using Bernoulli classifier.\n",
    "\n",
    "\n",
    "    # Instantiate our model and store it in a new variable.\n",
    "    bnb = BernoulliNB()\n",
    "\n",
    "    # Fit our model to the data.\n",
    "    bnb.fit(data, target)\n",
    "\n",
    "    # Classify, storing the result in a new variable.\n",
    "    y_pred = bnb.predict(data)\n",
    "    \n",
    "    total_points = data.shape[0]\n",
    "    wrong_points = (target != y_pred).sum()\n",
    "    score = bnb.score(data, target)\n",
    "    \n",
    "    \n",
    "    confusion = confusion_matrix(target, y_pred)\n",
    "    \n",
    "    return total_points, wrong_points, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 418, 0.582)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#womp womp\n",
    "naive_bayes_take_one(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second attempt... basically copying the thinkful naive bayes spam filter guided example\n",
    "\n",
    "def naive_bayes_take_two (dataframe):\n",
    "    \n",
    "    \"\"\"Train and test naive bayes \n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        dataframe (pd.DataFrame): \n",
    "            dataframe to use\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        total_points: \n",
    "            total number of texts classified\n",
    "        wrong_points: \n",
    "            number of texts incorrectly classified\n",
    "        score: \n",
    "            percent correctly classified\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    #cast everything to lowercase to make it easier to match words\n",
    "    df = dataframe\n",
    "    df = df.apply(lambda x: x.astype(str).str.lower())\n",
    "    \n",
    "    #picking keywords associated with bad reviews\n",
    "    keywords = ['unsatisfactory', 'disappointed', 'disappoint', 'junk', 'painful', 'unusable', 'negative']\n",
    "\n",
    "    for key in keywords:\n",
    "        # Noted adding spaces around keyword to make sure matching on word and not pattern\n",
    "        df[str(key)] = df.text.str.contains(\n",
    "            ' ' + str(key) + ' ',\n",
    "            case=False\n",
    "        )\n",
    "\n",
    "    data = df[keywords]\n",
    "    target = df['score']\n",
    "    \n",
    "    # Our data is binary / boolean so using Bernoulli classifier.\n",
    "\n",
    "\n",
    "    # Instantiate our model and store it in a new variable.\n",
    "    bnb = BernoulliNB()\n",
    "\n",
    "    # Fit our model to the data.\n",
    "    bnb.fit(data, target)\n",
    "\n",
    "    # Classify, storing the result in a new variable.\n",
    "    y_pred = bnb.predict(data)\n",
    "    \n",
    "    total_points = data.shape[0]\n",
    "    wrong_points = (target != y_pred).sum()\n",
    "    score = bnb.score(data, target)\n",
    "    \n",
    "    return total_points, wrong_points, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 492, 0.508)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so the positive words were better...\n",
    "naive_bayes_take_two(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#third attempt... what happens if I combine the positive and negative words together?\n",
    "\n",
    "def naive_bayes_take_three (dataframe):\n",
    "    \n",
    "    \"\"\"Train and test naive bayes \n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        dataframe (pd.DataFrame): \n",
    "            dataframe to use\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        total_points: \n",
    "            total number of texts classified\n",
    "        wrong_points: \n",
    "            number of texts incorrectly classified\n",
    "        score: \n",
    "            percent correctly classified\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    #cast everything to lowercase to make it easier to match words\n",
    "    df = dataframe\n",
    "    df = df.apply(lambda x: x.astype(str).str.lower())\n",
    "    \n",
    "    #picking keywords associated with good reviews\n",
    "    good = ['good', 'great', 'excellent', 'beautiful', 'best', 'satisfied']\n",
    "    \n",
    "    #picking keywords associated with bad reviews\n",
    "    bad = ['unsatisfactory', 'disappointed', 'disappoint', 'junk', 'painful', 'unusable', 'negative']\n",
    "    \n",
    "    keywords = good + bad\n",
    "\n",
    "    for key in bad:\n",
    "        # Noted adding spaces around keyword to make sure matching on word and not pattern\n",
    "        df[str(key)] = df.text.str.contains(\n",
    "            ' ' + str(key) + ' ',\n",
    "            case=False\n",
    "        )\n",
    "    \n",
    "    for key in good:\n",
    "        # Noted adding spaces around keyword to make sure matching on word and not pattern\n",
    "        df[str(key)] = df.text.str.contains(\n",
    "            ' ' + str(key) + ' ',\n",
    "            case=True\n",
    "        )\n",
    "    \n",
    "\n",
    "    data = df[keywords]\n",
    "    target = df['score']\n",
    "    \n",
    "    # Our data is binary / boolean so using Bernoulli classifier.\n",
    "\n",
    "\n",
    "    # Instantiate our model and store it in a new variable.\n",
    "    bnb = BernoulliNB()\n",
    "\n",
    "    # Fit our model to the data.\n",
    "    bnb.fit(data, target)\n",
    "\n",
    "    # Classify, storing the result in a new variable.\n",
    "    y_pred = bnb.predict(data)\n",
    "    \n",
    "    total_points = data.shape[0]\n",
    "    wrong_points = (target != y_pred).sum()\n",
    "    score = bnb.score(data, target)\n",
    "    \n",
    "    return total_points, wrong_points, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 418, 0.582)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#not any more accurate than the first attempt\n",
    "naive_bayes_take_three(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My feature engineering process was to look at several reviews and to select keywords that are associated with being either good or bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
